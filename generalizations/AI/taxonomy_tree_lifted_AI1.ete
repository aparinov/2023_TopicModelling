(mathematics of computing. human-centered computing[&&NHX:p=0:e=1:H={}:u=0.0:v=1.0:G={mathematics of computing. human-centered computing}:L={}:Hd=0:Ch=0:Sq=0],(information systems applications...internet of things 3 items[&&NHX:p=0:e=2:H={}:u=0.0:v=0.308:G={information systems applications...internet of things 3 items}:L={}:Hd=0:Ch=0:Sq=0],(document representation...specialized information retrieval 6 items[&&NHX:p=0:e=3:H={}:u=0.0:v=0.193:G={document representation...specialized information retrieval 6 items}:L={}:Hd=0:Ch=0:Sq=0],(rank aggregation...novelty in information retrieval 8 items[&&NHX:p=0:e=4:H={}:u=0.0:v=0.193:G={}:L={}:Hd=0:Ch=0:Sq=0],learning to rank[&&NHX:p=0.174:e=4:H={learning to rank}:u=0.193:v=0.193:G={}:L={}:Hd=1:Ch=0:Sq=1])retrieval models and ranking[&&NHX:p=0.174:e=3:H={learning to rank}:u=0.193:v=0.193:G={rank aggregation;...;novelty in information retrieval}:L={}:Hd=0:Ch=1:Sq=0])information retrieval[&&NHX:p=0.174:e=2:H={learning to rank}:u=0.193:v=0.308:G={document representation;...;novelty in information retrieval}:L={}:Hd=0:Ch=1:Sq=0],(database design and models...information integration 4 items[&&NHX:p=0:e=3:H={}:u=0.0:v=0.24:G={database design and models...information integration 4 items}:L={}:Hd=0:Ch=0:Sq=0],(dbms engine architectures...big data 12 items[&&NHX:p=0:e=4:H={}:u=0.0:v=0.24:G={dbms engine architectures...big data 12 items}:L={}:Hd=0:Ch=0:Sq=0],(distributed data locking. deadlocks[&&NHX:p=0:e=5:H={}:u=0.0:v=0.24:G={}:L={}:Hd=0:Ch=0:Sq=0],distributed database recovery[&&NHX:p=0.216:e=5:H={distributed database recovery}:u=0.24:v=0.24:G={}:L={}:Hd=1:Ch=0:Sq=1])distributed database transactions[&&NHX:p=0.216:e=4:H={distributed database recovery}:u=0.24:v=0.24:G={distributed data locking;deadlocks}:L={}:Hd=0:Ch=1:Sq=0])database management system engines[&&NHX:p=0.216:e=3:H={distributed database recovery}:u=0.24:v=0.24:G={dbms engine architectures;...;deadlocks}:L={}:Hd=0:Ch=1:Sq=0])data management systems[&&NHX:p=0.216:e=2:H={distributed database recovery}:u=0.24:v=0.308:G={database design and models;...;deadlocks}:L={}:Hd=0:Ch=1:Sq=0])information systems[&&NHX:p=0.39:e=1:H={distributed database recovery;learning to rank}:u=0.308:v=1.0:G={information systems applications;...;novelty in information retrieval}:L={}:Hd=0:Ch=1:Sq=0],(database theory[&&NHX:p=0:e=2:H={}:u=0.0:v=0.659:G={database theory}:L={}:Hd=0:Ch=0:Sq=0],(sample complexity and generalization bounds...regret bounds 16 items[&&NHX:p=0:e=3:H={}:u=0.0:v=0.659:G={}:L={}:Hd=0:Ch=0:Sq=0],(sequential decision making. adversarial learning[&&NHX:p=0:e=4:H={}:u=0.0:v=0.659:G={}:L={}:Hd=0:Ch=0:Sq=1],inverse reinforcement learning[&&NHX:p=0.293:e=4:H={inverse reinforcement learning}:u=0.325:v=0.659:G={}:L={}:Hd=0:Ch=0:Sq=1],multi-agent reinforcement learning[&&NHX:p=0.339:e=4:H={multi-agent reinforcement learning}:u=0.377:v=0.659:G={}:L={}:Hd=0:Ch=0:Sq=1],apprenticeship learning[&&NHX:p=0.388:e=4:H={apprenticeship learning}:u=0.431:v=0.659:G={}:L={}:Hd=0:Ch=0:Sq=1])reinforcement learning[&&NHX:p=0.922:e=3:H={reinforcement learning}:u=0.659:v=0.659:G={sequential decision making;adversarial learning}:L={sequential decision making;adversarial learning}:Hd=1:Ch=1:Sq=1])machine learning theory[&&NHX:p=0.922:e=2:H={reinforcement learning}:u=0.659:v=0.659:G={sample complexity and generalization bounds;...;adversarial learning}:L={sequential decision making;adversarial learning}:Hd=0:Ch=1:Sq=0])theory of computation[&&NHX:p=0.922:e=1:H={reinforcement learning}:u=0.659:v=1.0:G={database theory;...;adversarial learning}:L={sequential decision making;adversarial learning}:Hd=0:Ch=1:Sq=0],(artificial intelligence[&&NHX:p=0:e=2:H={}:u=0.0:v=0.686:G={artificial intelligence}:L={}:Hd=0:Ch=0:Sq=0],(learning settings...deep learning 5 items[&&NHX:p=0:e=3:H={}:u=0.0:v=0.686:G={learning settings...deep learning 5 items}:L={}:Hd=0:Ch=0:Sq=0],(unsupervised learning. multi-task learning[&&NHX:p=0:e=4:H={}:u=0.0:v=0.686:G={unsupervised learning. multi-task learning}:L={}:Hd=0:Ch=0:Sq=0],(ranking...cost-sensitive learning 5 items[&&NHX:p=0:e=5:H={}:u=0.0:v=0.193:G={}:L={}:Hd=0:Ch=0:Sq=0],learning to rank[&&NHX:p=0.174:e=5:H={learning to rank}:u=0.193:v=0.193:G={}:L={}:Hd=1:Ch=0:Sq=1])supervised learning[&&NHX:p=0.174:e=4:H={learning to rank}:u=0.193:v=0.686:G={ranking;...;cost-sensitive learning}:L={}:Hd=0:Ch=1:Sq=0],(sequential decision making. adversarial learning[&&NHX:p=0:e=5:H={}:u=0.0:v=0.659:G={}:L={}:Hd=0:Ch=0:Sq=1],inverse reinforcement learning[&&NHX:p=0.293:e=5:H={inverse reinforcement learning}:u=0.325:v=0.659:G={}:L={}:Hd=0:Ch=0:Sq=1],multi-agent reinforcement learning[&&NHX:p=0.339:e=5:H={multi-agent reinforcement learning}:u=0.377:v=0.659:G={}:L={}:Hd=0:Ch=0:Sq=1],apprenticeship learning[&&NHX:p=0.388:e=5:H={apprenticeship learning}:u=0.431:v=0.659:G={}:L={}:Hd=0:Ch=0:Sq=1])reinforcement learning[&&NHX:p=0.922:e=4:H={reinforcement learning}:u=0.659:v=0.686:G={sequential decision making;adversarial learning}:L={sequential decision making;adversarial learning}:Hd=1:Ch=1:Sq=1])learning paradigms[&&NHX:p=1.096:e=3:H={learning to rank;reinforcement learning}:u=0.686:v=0.686:G={unsupervised learning;...;adversarial learning}:L={sequential decision making;adversarial learning}:Hd=0:Ch=1:Sq=0])machine learning[&&NHX:p=1.096:e=2:H={learning to rank;reinforcement learning}:u=0.686:v=0.686:G={learning settings;...;adversarial learning}:L={sequential decision making;adversarial learning}:Hd=0:Ch=1:Sq=0])computing methodologies[&&NHX:p=1.096:e=1:H={learning to rank;reinforcement learning}:u=0.686:v=1.0:G={artificial intelligence;...;adversarial learning}:L={sequential decision making;adversarial learning}:Hd=0:Ch=1:Sq=0])root[&&NHX:p=2.408:e=0:H={reinforcement learning;...;reinforcement learning}:u=1.0:v=1.0:G={mathematics of computing;...;cost-sensitive learning}:L={sequential decision making;...;adversarial learning}:Hd=0:Ch=1:Sq=0];