{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "879dafbf-b64e-433e-adc9-5677cf6e782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274fdf2-f77f-49e5-8324-87e7a8b2acd1",
   "metadata": {},
   "source": [
    "# Pre-preprocessing\n",
    " - (пришлось отредактировать 14 строку 3 листа, там странный формат id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e56b387e-2ecd-460a-8262-fabee48d28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    pd.read_excel(\"Taxonomy examples (edited).xlsx\", sheet_name=i - 1, header=None).to_csv(f\"tree{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a7b1fae-609e-49cd-bf85-c48edf63a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_csv(file_path):\n",
    "    \"\"\"\n",
    "    Auxiliary function for specific dataset.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        stripped_lines = [line[1:-2] for line in file]\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write('\\n'.join(stripped_lines[1:]))\n",
    "        \n",
    "for file in ['tree1.csv', 'tree2.csv', 'tree3.csv']:\n",
    "    strip_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd1893e5-c764-4163-b27a-261bb9690f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.2.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.2.1.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data cleaning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2.1.2.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Collaborative filtering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2.1.2.1*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item-based</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.2.1.2.2*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scalable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   0   1            2                        3           4   5  \\\n",
       "0      3.2.1. NaN NaN  Data mining                      NaN         NaN NaN   \n",
       "1    3.2.1.1. NaN NaN          NaN            Data cleaning         NaN NaN   \n",
       "2    3.2.1.2. NaN NaN          NaN  Collaborative filtering         NaN NaN   \n",
       "3  3.2.1.2.1* NaN NaN          NaN                      NaN  Item-based NaN   \n",
       "4  3.2.1.2.2* NaN NaN          NaN                      NaN    Scalable NaN   \n",
       "\n",
       "    6   7   8   9  \n",
       "0 NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN  \n",
       "4 NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naming = [\"id\"]+list(range(10))\n",
    "df1 = pd.read_csv('tree1.csv', names=naming)\n",
    "df2 = pd.read_csv('tree2.csv', names=naming)\n",
    "df3 = pd.read_csv('tree3.csv', names=naming)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c6e690b7-e535-4f41-968e-74c4cec8ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = r\"[*.]+(?!.*[*.])\" # Matches tracing symbol (either ., * or **), did not find interpretation of it\n",
    "df1[\"id\"] = df1[\"id\"].str.replace(reg, \"\")\n",
    "df2[\"id\"] = df2[\"id\"].str.replace(reg, \"\")\n",
    "df3[\"id\"] = df3[\"id\"].str.replace(reg, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0115bf-9af2-49f0-a269-43064332bf19",
   "metadata": {},
   "source": [
    "# DF to directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "84abd745-f2a0-4bdb-9151-e7e1800f8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0d738476-a806-4fa1-95d0-e241b38b68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "def df_to_graph(data):\n",
    "    \"\"\"\n",
    "    Auxiliary function to transform dataframe into nx.DiGraph\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    for r in data.iterrows():\n",
    "        index = str(r[1].id)\n",
    "        name = r[1][~r[1].isna()].iloc[1]\n",
    "        G.add_node(name)\n",
    "        \n",
    "        parent_index = index[:-len(re.findall(r\"\\d+(?!.*\\d+)\", index)[0])-1]\n",
    "        parent = data[data.id == parent_index]\n",
    "        if parent.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "            \n",
    "        parent = parent.iloc[0]\n",
    "        parent_name = parent[~parent.isna()].values[1]  \n",
    "        \n",
    "        if parent_name in G:\n",
    "            G.add_edge(parent_name, name)\n",
    "            \n",
    "    return G\n",
    "    \n",
    "tree1 = df_to_graph(df1)\n",
    "tree2 = df_to_graph(df2)\n",
    "tree3 = df_to_graph(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0f499c7b-e665-4321-bace-06f0380a5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree1.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "df5faa41-5822-4622-9ace-8141d86e4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree2.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "46e87668-900f-4491-9149-710bf00ba702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_leaves(graph, node): # Redundant function\n",
    "#     leaves = []\n",
    "#     for u, children in nx.dfs_successors(graph, node).items():\n",
    "#         for v in children:\n",
    "#             if graph.out_degree(v) == 0:\n",
    "#                 leaves.append(v)\n",
    "#     return leaves\n",
    "\n",
    "# get_leaves(tree2, 'Sequence mining')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2e7f6-286b-48c1-9f1a-54f88c1dc0d5",
   "metadata": {},
   "source": [
    "# Least Common Ancestor mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eb8fdb6a-8940-4d87-a8cb-0f0bc83aa8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data mining'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def least_common_ancestor(graph: nx.DiGraph, nodes: list):\n",
    "    \"\"\"\n",
    "    Least common ancestor: the 'deepest' node in graph, containing all nodes as successors.\n",
    "    \"\"\"\n",
    "    ancestors = [set(nx.ancestors(graph, node)) for node in nodes]\n",
    "    common_ancestors = set.intersection(*ancestors)\n",
    "    \n",
    "    return min(common_ancestors, key=lambda x: len(nx.shortest_path(graph, x, nodes[0])) - 1)\n",
    "\n",
    "least_common_ancestor(tree2, ['Rule and pattern discovery', 'Trajectory clustering', 'Types of association rules'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a75f9f62-29d0-4f42-9768-1f83826925e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data mining': 'Data mining', 'Data cleaning': 'Data cleaning', 'Collaborative filtering': 'Collaborative filtering', 'Item-based': 'Item-based', 'Scalable': 'Scalable', 'Association rules': 'Association rules', 'Types of association rules': 'Types of association rules', 'Interestingness': 'Interestingness', 'Parallel computation': 'Parallel computation', 'Clustering': 'Clustering', 'Massive data clustering': 'Massive data clustering', 'Consensus clustering': 'Consensus clustering', 'Fuzzy clustering': 'Fuzzy clustering', 'Additive clustering': 'Additive clustering', 'Feature weight clustering': 'Feature weight clustering', 'Conceptual clustering': 'Conceptual clustering', 'Biclustering': 'Biclustering', 'Nearest-neighbor search': 'Nearest-neighbor search', 'Data stream mining': 'Data stream mining', 'Graph mining': 'Graph mining', 'Graph partitioning': 'Graph partitioning', 'Frequent graph mining': 'Frequent graph mining', 'Graph based conceptual clustering': 'Graph based conceptual clustering', 'Anomaly detection': 'Anomaly detection', 'Critical nodes detection': 'Critical nodes detection', 'Process mining': 'Process mining', 'Text mining': 'Text mining', 'Text categorization': 'Text categorization', 'Key-phrase indexing': 'Key-phrase indexing', 'Data mining tools': 'Data mining tools', 'Sequence mining': 'Sequence mining', 'Rule and pattern discovery': 'Rule and pattern discovery', 'Trajectory clustering': 'Trajectory clustering', 'Market graph': 'Market graph', 'Formal concept analysis': 'Formal concept analysis'}\n"
     ]
    }
   ],
   "source": [
    "def map_tree(treeG: nx.DiGraph, treeS: nx.DiGraph):\n",
    "    \"\"\"\n",
    "    Least common ancestor mapping. (Assumes presence of all nodes from treeG in treeS.)\n",
    "    \n",
    "    Maps every node X from treeG to least common ancestor node of all successors of X from treeG in treeS (unless it does not have any, in which case maps it to itself).\n",
    "    \"\"\"\n",
    "    mappings = []\n",
    "    for node in treeG.nodes:\n",
    "        if treeG.in_degree(node) != 0 and treeG.out_degree(node) != 0:\n",
    "            successors = list(nx.dfs_successors(treeG, node).values())[0]\n",
    "            lca = least_common_ancestor(treeS, successors)\n",
    "\n",
    "            mappings += [(node, lca)]\n",
    "            # print(f\"{node} ---> {lca}\")\n",
    "        else:\n",
    "            mappings += [(node, node)]\n",
    "            # print(f\"{node} ---> {node}\")\n",
    "    \n",
    "    mappings = {key: value for (key, value) in mappings}\n",
    "    return mappings\n",
    "            \n",
    "        \n",
    "print(map_tree(tree1, tree3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dfd2d-da7d-4917-b7ff-03f4bffa817e",
   "metadata": {},
   "source": [
    "# Duplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "630b3409-3974-4051-ab1a-e74a4c2a3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplications(treeG: nx.DiGraph, treeS: nx.DiGraph, mappings=None):\n",
    "    \"\"\"\n",
    "    Function for determining the duplications in two mapped trees.\n",
    "    Partial duplication - node in treeG, one of whose children's mapping is the same as its own.\n",
    "    Full duplication - node in treeG, all of whose childrens' mappings are the same as its own.\n",
    "    \n",
    "    Returns two lists: full duplications and partial duplications.\n",
    "    \"\"\"\n",
    "    partial = []                                           # Analogy for one-side duplications\n",
    "    full = []                                              # Analogy for two-side duplications\n",
    "    \n",
    "    if not mappings:\n",
    "        mappings = map_tree(treeG, treeS)\n",
    "        \n",
    "    \n",
    "    for m in mappings:\n",
    "        own = mappings[m]\n",
    "        children = [mappings[s] for s in treeG.successors(m)]\n",
    "        \n",
    "        is_full = bool(children)                           # So that leaves are not considered two-side duplications\n",
    "        is_partial = False\n",
    "        for c in children:\n",
    "            if c != own:\n",
    "                is_full = False\n",
    "            else:\n",
    "                is_partial = True\n",
    "        \n",
    "        if is_full:\n",
    "            full.append(m)\n",
    "        elif is_partial:\n",
    "            partial.append(m)\n",
    "        \n",
    "    return full, partial\n",
    "\n",
    "# get_duplications(tree1, tree3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ab2e1c5d-620d-4613-885c-6d2a43f175ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_tree = df_to_graph(pd.read_csv('genetree.csv', names=[\"id\"]+list(range(5))))\n",
    "species_tree = df_to_graph(pd.read_csv('speciestree.csv', names=[\"id\"]+list(range(5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f3905daa-0a6c-4b42-b911-4062cf3f6370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'a',\n",
       " 'b': 'a',\n",
       " 'c': 'c',\n",
       " 'd': 'c',\n",
       " 'one': 'one',\n",
       " 'two': 'two',\n",
       " 'three': 'three',\n",
       " 'e': 'g',\n",
       " 'four': 'four',\n",
       " 'five': 'five',\n",
       " 'f': 'a',\n",
       " 'six': 'six',\n",
       " 'g': 'e',\n",
       " 'seven': 'seven',\n",
       " 'eight': 'eight'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_tree(gene_tree, species_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "81ca5857-ec7a-4ad4-bbc1-34d94af3d018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['a'], ['c'])\n"
     ]
    }
   ],
   "source": [
    "print(get_duplications(gene_tree, species_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9059fd-8f46-4319-bca2-2dc4c5930073",
   "metadata": {},
   "source": [
    "# Intermediate nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "29de5b33-20e7-4f6a-921d-0c0d2822fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_intermediates(treeG: nx.DiGraph, treeS: nx.DiGraph, mappings=None, root=None):\n",
    "    \"\"\"\n",
    "    Function to get the number of intermediate nodes in two mapped trees.\n",
    "    For node g in treeG, nodes in treeS are called intermediate if they \"lie inbetween\" g's mapping and g's parent's mapping.\n",
    "    \n",
    "    Returns integer - number of intermediate nodes.\n",
    "    \"\"\"\n",
    "    intermediates = 0\n",
    "    \n",
    "    if not mappings:\n",
    "        mappings = map_tree(treeG, treeS)\n",
    "        \n",
    "    if not root:\n",
    "        root = list(mappings.keys())[0]                     # Костыль, лучше заранее сохранять корень (или переехать с networkx на ete3)\n",
    "        \n",
    "    for node in treeG.nodes:\n",
    "        parent = next(treeG.predecessors(node), None)\n",
    "        if not parent:\n",
    "            continue\n",
    "            \n",
    "        kek = max(nx.shortest_path_length(treeS, mappings[parent], mappings[node]) - 1, 0)\n",
    "        intermediates += kek\n",
    "        \n",
    "        \n",
    "    return intermediates\n",
    "    \n",
    "get_intermediates(gene_tree, species_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07133783-26db-444a-a074-6ab75f90ffc1",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "45efc24e-91ea-4158-8949-cc99d57b651c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_cost(treeG: nx.DiGraph, treeS: nx.DiGraph, mappings=None, root=None):\n",
    "    partial_duplications = len(get_duplications(treeG, treeS, mappings)[1])\n",
    "    intermediates = get_intermediates(treeG, treeS, mappings, root)\n",
    "    \n",
    "    return partial_duplications + intermediates\n",
    "\n",
    "tree_cost(gene_tree, species_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f57d4-5342-4cde-8d91-08948891a6e3",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c6f28270-469f-4cb4-bb5d-d0cdb429621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ete3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4a7d4a6e-1085-4cc2-a7a8-0b6d6e536164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ete(initial: nx.DiGraph):\n",
    "    \"\"\"\n",
    "    Auxiliary function that converts nx.DiGraph to an ete3 Tree in order to simplify visualization.\n",
    "    \"\"\"\n",
    "    subtrees = {node:ete3.Tree(name=node) for node in initial.nodes()}\n",
    "    [*map(lambda edge:subtrees[edge[0]].add_child(subtrees[edge[1]]), initial.edges())]\n",
    "    \n",
    "    return subtrees[list(initial.nodes)[0]]\n",
    "\n",
    "# print(convert_to_ete(tree1).get_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c8bda665-534c-48ac-b9c1-3f824a7bf8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            /-one\n",
      "         /d|\n",
      "      /c|   \\-two\n",
      "     |  |\n",
      "   /b|   \\-three\n",
      "  |  |\n",
      "  |  |   /-four\n",
      "-a|   \\e|\n",
      "  |      \\-five\n",
      "  |\n",
      "  |   /-six\n",
      "   \\f|\n",
      "     |   /-seven\n",
      "      \\g|\n",
      "         \\-eight\n"
     ]
    }
   ],
   "source": [
    "print(convert_to_ete(gene_tree).get_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f41687e8-50f0-4bbd-9637-accc43bcaf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            /-one\n",
      "         /d|\n",
      "      /c|   \\-three\n",
      "     |  |\n",
      "   /b|   \\-two\n",
      "  |  |\n",
      "  |   \\-six\n",
      "  |\n",
      "-a|         /-four\n",
      "  |      /g|\n",
      "  |   /f|   \\-five\n",
      "  |  |  |\n",
      "   \\e|   \\-seven\n",
      "     |\n",
      "      \\-eight\n"
     ]
    }
   ],
   "source": [
    "print(convert_to_ete(species_tree).get_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f71a5f-48dd-4266-b93b-c535d4197001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
