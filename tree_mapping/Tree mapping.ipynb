{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "879dafbf-b64e-433e-adc9-5677cf6e782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274fdf2-f77f-49e5-8324-87e7a8b2acd1",
   "metadata": {},
   "source": [
    "# Pre-preprocessing\n",
    " - (пришлось отредактировать 14 строку 3 листа, там странный формат id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56b387e-2ecd-460a-8262-fabee48d28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    pd.read_excel(\"Taxonomy examples (edited).xlsx\", sheet_name=i - 1, header=None).to_csv(f\"tree{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7b1fae-609e-49cd-bf85-c48edf63a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_csv(file_path):\n",
    "    \"\"\"\n",
    "    Auxiliary function for specific dataset.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        stripped_lines = [line[1:-2] for line in file]\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write('\\n'.join(stripped_lines[1:]))\n",
    "        \n",
    "for file in ['tree1.csv', 'tree2.csv', 'tree3.csv']:\n",
    "    strip_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1893e5-c764-4163-b27a-261bb9690f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.2.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.2.1.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data cleaning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2.1.2.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Collaborative filtering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2.1.2.1*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item-based</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.2.1.2.2*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scalable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   0   1            2                        3           4   5  \\\n",
       "0      3.2.1. NaN NaN  Data mining                      NaN         NaN NaN   \n",
       "1    3.2.1.1. NaN NaN          NaN            Data cleaning         NaN NaN   \n",
       "2    3.2.1.2. NaN NaN          NaN  Collaborative filtering         NaN NaN   \n",
       "3  3.2.1.2.1* NaN NaN          NaN                      NaN  Item-based NaN   \n",
       "4  3.2.1.2.2* NaN NaN          NaN                      NaN    Scalable NaN   \n",
       "\n",
       "    6   7   8   9  \n",
       "0 NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN  \n",
       "4 NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naming = [\"id\"]+list(range(10))\n",
    "df1 = pd.read_csv('tree1.csv', names=naming)\n",
    "df2 = pd.read_csv('tree2.csv', names=naming)\n",
    "df3 = pd.read_csv('tree3.csv', names=naming)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6e690b7-e535-4f41-968e-74c4cec8ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = r\"[*.]+(?!.*[*.])\" # Matches tracing symbol (either ., * or **), did not find interpretation of it\n",
    "df1[\"id\"] = df1[\"id\"].str.replace(reg, \"\")\n",
    "df2[\"id\"] = df2[\"id\"].str.replace(reg, \"\")\n",
    "df3[\"id\"] = df3[\"id\"].str.replace(reg, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0115bf-9af2-49f0-a269-43064332bf19",
   "metadata": {},
   "source": [
    "# DF to directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84abd745-f2a0-4bdb-9151-e7e1800f8f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\mcseem\\anaconda3\\lib\\site-packages (2.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d738476-a806-4fa1-95d0-e241b38b68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "def df_to_graph(data):\n",
    "    \"\"\"\n",
    "    Auxiliary function to transform dataframe into nx.DiGraph\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    for r in data.iterrows():\n",
    "        index = str(r[1].id)\n",
    "        name = r[1][~r[1].isna()].iloc[1]\n",
    "        G.add_node(name)\n",
    "        \n",
    "        parent_index = index[:-len(re.findall(r\"\\d+(?!.*\\d+)\", index)[0])-1]\n",
    "        parent = data[data.id == parent_index]\n",
    "        if parent.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "            \n",
    "        parent = parent.iloc[0]\n",
    "        parent_name = parent[~parent.isna()].values[1]  \n",
    "        \n",
    "        if parent_name in G:\n",
    "            G.add_edge(parent_name, name)\n",
    "            \n",
    "    return G\n",
    "    \n",
    "tree1 = df_to_graph(df1)\n",
    "tree2 = df_to_graph(df2)\n",
    "tree3 = df_to_graph(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f499c7b-e665-4321-bace-06f0380a5b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('Data mining', 'Data cleaning', 'Collaborative filtering', 'Item-based', 'Scalable', 'Association rules', 'Types of association rules', 'Interestingness', 'Parallel computation', 'Clustering', 'Massive data clustering', 'Consensus clustering', 'Fuzzy clustering', 'Additive clustering', 'Feature weight clustering', 'Conceptual clustering', 'Biclustering', 'Nearest-neighbor search', 'Data stream mining', 'Graph mining', 'Graph partitioning', 'Frequent graph mining', 'Graph based conceptual clustering', 'Anomaly detection', 'Critical nodes detection', 'Process mining', 'Text mining', 'Text categorization', 'Key-phrase indexing', 'Data mining tools', 'Sequence mining', 'Rule and pattern discovery', 'Trajectory clustering', 'Market graph', 'Formal concept analysis'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5faa41-5822-4622-9ace-8141d86e4038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([('Data mining', 'Data cleaning'), ('Data mining', 'Collaborative filtering'), ('Data mining', 'Association rules'), ('Data mining', 'Clustering'), ('Data mining', 'Nearest-neighbor search'), ('Data mining', 'Other  mining'), ('Data mining', 'Formal concept analysis'), ('Collaborative filtering', 'Item-based'), ('Collaborative filtering', 'Scalable'), ('Association rules', 'Types of association rules'), ('Association rules', 'Interestingness'), ('Association rules', 'Parallel computation'), ('Clustering', 'Massive data clustering'), ('Clustering', 'Consensus clustering'), ('Clustering', 'Fuzzy clustering'), ('Clustering', 'Additive clustering'), ('Clustering', 'Feature weight clustering'), ('Clustering', 'Conceptual clustering'), ('Clustering', 'Biclustering'), ('Other  mining', 'Data stream mining'), ('Other  mining', 'Graph mining'), ('Other  mining', 'Process mining'), ('Other  mining', 'Text mining'), ('Other  mining', 'Data mining tools'), ('Other  mining', 'Sequence mining'), ('Graph mining', 'Graph partitioning'), ('Graph mining', 'Frequent graph mining'), ('Graph mining', 'Graph based conceptual clustering'), ('Graph mining', 'Anomaly detection'), ('Graph mining', 'Critical nodes detection'), ('Text mining', 'Text categorization'), ('Text mining', 'Key-phrase indexing'), ('Sequence mining', 'Rule and pattern discovery'), ('Sequence mining', 'Trajectory clustering'), ('Sequence mining', 'Market graph')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree2.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e87668-900f-4491-9149-710bf00ba702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_leaves(graph, node): # Redundant function\n",
    "#     leaves = []\n",
    "#     for u, children in nx.dfs_successors(graph, node).items():\n",
    "#         for v in children:\n",
    "#             if graph.out_degree(v) == 0:\n",
    "#                 leaves.append(v)\n",
    "#     return leaves\n",
    "\n",
    "# get_leaves(tree2, 'Sequence mining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8fdb6a-8940-4d87-a8cb-0f0bc83aa8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data mining'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def least_common_ancestor(graph: nx.DiGraph, nodes: list):\n",
    "    \"\"\"\n",
    "    Least common ancestor: the 'deepest' node in graph, containing all nodes as successors.\n",
    "    \"\"\"\n",
    "    ancestors = [set(nx.ancestors(graph, node)) for node in nodes]\n",
    "    common_ancestors = set.intersection(*ancestors)\n",
    "    \n",
    "    return min(common_ancestors, key=lambda x: len(nx.shortest_path(graph, x, nodes[0])) - 1) # rework\n",
    "\n",
    "least_common_ancestor(tree2, ['Rule and pattern discovery', 'Trajectory clustering', 'Types of association rules'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a75f9f62-29d0-4f42-9768-1f83826925e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mining ---> Data mining\n",
      "Data cleaning ---> Data cleaning\n",
      "Collaborative filtering ---> Collaborative filtering\n",
      "Item-based ---> Item-based\n",
      "Scalable ---> Scalable\n",
      "Association rules ---> Association rules\n",
      "Types of association rules ---> Types of association rules\n",
      "Interestingness ---> Interestingness\n",
      "Parallel computation ---> Parallel computation\n",
      "Clustering ---> Clustering\n",
      "Massive data clustering ---> Massive data clustering\n",
      "Consensus clustering ---> Consensus clustering\n",
      "Fuzzy clustering ---> Fuzzy clustering\n",
      "Additive clustering ---> Additive clustering\n",
      "Feature weight clustering ---> Feature weight clustering\n",
      "Conceptual clustering ---> Conceptual clustering\n",
      "Biclustering ---> Biclustering\n",
      "Nearest-neighbor search ---> Nearest-neighbor search\n",
      "Data stream mining ---> Data stream mining\n",
      "Graph mining ---> Graph mining\n",
      "Graph partitioning ---> Graph partitioning\n",
      "Frequent graph mining ---> Frequent graph mining\n",
      "Graph based conceptual clustering ---> Graph based conceptual clustering\n",
      "Anomaly detection ---> Anomaly detection\n",
      "Critical nodes detection ---> Critical nodes detection\n",
      "Process mining ---> Process mining\n",
      "Text mining ---> Text mining\n",
      "Text categorization ---> Text categorization\n",
      "Key-phrase indexing ---> Key-phrase indexing\n",
      "Data mining tools ---> Data mining tools\n",
      "Sequence mining ---> Sequence mining\n",
      "Rule and pattern discovery ---> Rule and pattern discovery\n",
      "Trajectory clustering ---> Trajectory clustering\n",
      "Market graph ---> Market graph\n",
      "Formal concept analysis ---> Formal concept analysis\n",
      "[('Data mining', 'Data mining'), ('Data cleaning', 'Data cleaning'), ('Collaborative filtering', 'Collaborative filtering'), ('Item-based', 'Item-based'), ('Scalable', 'Scalable'), ('Association rules', 'Association rules'), ('Types of association rules', 'Types of association rules'), ('Interestingness', 'Interestingness'), ('Parallel computation', 'Parallel computation'), ('Clustering', 'Clustering'), ('Massive data clustering', 'Massive data clustering'), ('Consensus clustering', 'Consensus clustering'), ('Fuzzy clustering', 'Fuzzy clustering'), ('Additive clustering', 'Additive clustering'), ('Feature weight clustering', 'Feature weight clustering'), ('Conceptual clustering', 'Conceptual clustering'), ('Biclustering', 'Biclustering'), ('Nearest-neighbor search', 'Nearest-neighbor search'), ('Data stream mining', 'Data stream mining'), ('Graph mining', 'Graph mining'), ('Graph partitioning', 'Graph partitioning'), ('Frequent graph mining', 'Frequent graph mining'), ('Graph based conceptual clustering', 'Graph based conceptual clustering'), ('Anomaly detection', 'Anomaly detection'), ('Critical nodes detection', 'Critical nodes detection'), ('Process mining', 'Process mining'), ('Text mining', 'Text mining'), ('Text categorization', 'Text categorization'), ('Key-phrase indexing', 'Key-phrase indexing'), ('Data mining tools', 'Data mining tools'), ('Sequence mining', 'Sequence mining'), ('Rule and pattern discovery', 'Rule and pattern discovery'), ('Trajectory clustering', 'Trajectory clustering'), ('Market graph', 'Market graph'), ('Formal concept analysis', 'Formal concept analysis')]\n"
     ]
    }
   ],
   "source": [
    "def map_tree(treeG: nx.DiGraph, treeS: nx.DiGraph):\n",
    "    \"\"\"\n",
    "    Least common ancestor mapping. (Assumes presence of all nodes from treeG in treeS.)\n",
    "    \n",
    "    Maps every node X from treeG to least common ancestor node of all successors of X from treeG in treeS (unless it does not have any, in which case maps it to itself).\n",
    "    \"\"\"\n",
    "    mappings = []\n",
    "    for node in treeG.nodes:\n",
    "        if treeG.in_degree(node) != 0 and treeG.out_degree(node) != 0:\n",
    "            successors = list(nx.dfs_successors(treeG, node).values())[0]\n",
    "            lca = least_common_ancestor(treeS, successors)\n",
    "\n",
    "            mappings += [(node, lca)]\n",
    "            print(f\"{node} ---> {lca}\")\n",
    "        else:\n",
    "            mappings += [(node, node)]\n",
    "            print(f\"{node} ---> {node}\")\n",
    "    \n",
    "    return mappings\n",
    "            \n",
    "        \n",
    "print(map_tree(tree1, tree3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6f28270-469f-4cb4-bb5d-d0cdb429621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ete3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a7d4a6e-1085-4cc2-a7a8-0b6d6e536164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           /-Data cleaning\n",
      "          |\n",
      "          |                       /-Item-based\n",
      "          |-Collaborative filtering\n",
      "          |                       \\-Scalable\n",
      "          |\n",
      "          |                 /-Types of association rules\n",
      "          |                |\n",
      "          |-Association rules-Interestingness\n",
      "          |                |\n",
      "          |                 \\-Parallel computation\n",
      "          |\n",
      "          |          /-Massive data clustering\n",
      "          |         |\n",
      "          |         |--Consensus clustering\n",
      "          |         |\n",
      "          |         |--Fuzzy clustering\n",
      "          |         |\n",
      "          |-Clustering-Additive clustering\n",
      "          |         |\n",
      "          |         |--Feature weight clustering\n",
      "          |         |\n",
      "          |         |--Conceptual clustering\n",
      "          |         |\n",
      "          |          \\-Biclustering\n",
      "          |\n",
      "          |--Nearest-neighbor search\n",
      "-Data mining\n",
      "          |--Data stream mining\n",
      "          |\n",
      "          |            /-Graph partitioning\n",
      "          |           |\n",
      "          |           |--Frequent graph mining\n",
      "          |           |\n",
      "          |-Graph mining-Graph based conceptual clustering\n",
      "          |           |\n",
      "          |           |--Anomaly detection\n",
      "          |           |\n",
      "          |            \\-Critical nodes detection\n",
      "          |\n",
      "          |--Process mining\n",
      "          |\n",
      "          |           /-Text categorization\n",
      "          |-Text mining\n",
      "          |           \\-Key-phrase indexing\n",
      "          |\n",
      "          |--Data mining tools\n",
      "          |\n",
      "          |               /-Rule and pattern discovery\n",
      "          |              |\n",
      "          |-Sequence mining-Trajectory clustering\n",
      "          |              |\n",
      "          |               \\-Market graph\n",
      "          |\n",
      "           \\-Formal concept analysis\n"
     ]
    }
   ],
   "source": [
    "def convert_to_ete(initial: nx.DiGraph):\n",
    "    \"\"\"\n",
    "    Auxiliary function that converts nx.DiGraph to an ete3 Tree in order to simplify visualization.\n",
    "    \"\"\"\n",
    "    subtrees = {node:ete3.Tree(name=node) for node in initial.nodes()}\n",
    "    [*map(lambda edge:subtrees[edge[0]].add_child(subtrees[edge[1]]), initial.edges())]\n",
    "    \n",
    "    return subtrees[list(tree1.nodes)[0]]\n",
    "\n",
    "print(convert_to_ete(tree1).get_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f41687e8-50f0-4bbd-9637-accc43bcaf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           /-Data cleaning\n",
      "          |\n",
      "          |                       /-Item-based\n",
      "          |-Collaborative filtering\n",
      "          |                       \\-Scalable\n",
      "          |\n",
      "          |                 /-Types of association rules\n",
      "          |                |\n",
      "          |-Association rules-Interestingness\n",
      "          |                |\n",
      "          |                 \\-Parallel computation\n",
      "          |\n",
      "          |          /-Massive data clustering\n",
      "          |         |\n",
      "          |         |--Consensus clustering\n",
      "          |         |\n",
      "          |         |--Fuzzy clustering\n",
      "          |         |\n",
      "          |-Clustering-Additive clustering\n",
      "          |         |\n",
      "          |         |--Feature weight clustering\n",
      "          |         |\n",
      "          |         |--Conceptual clustering\n",
      "          |         |\n",
      "          |          \\-Biclustering\n",
      "          |\n",
      "          |--Nearest-neighbor search\n",
      "-Data mining\n",
      "          |             /-Data stream mining\n",
      "          |            |\n",
      "          |            |            /-Graph partitioning\n",
      "          |            |           |\n",
      "          |            |           |--Frequent graph mining\n",
      "          |            |           |\n",
      "          |            |-Graph mining-Graph based conceptual clustering\n",
      "          |            |           |\n",
      "          |            |           |--Anomaly detection\n",
      "          |            |           |\n",
      "          |            |            \\-Critical nodes detection\n",
      "          |-Other  mining\n",
      "          |            |--Process mining\n",
      "          |            |\n",
      "          |            |           /-Text categorization\n",
      "          |            |-Text mining\n",
      "          |            |           \\-Key-phrase indexing\n",
      "          |            |\n",
      "          |            |--Data mining tools\n",
      "          |            |\n",
      "          |            |               /-Rule and pattern discovery\n",
      "          |            |              |\n",
      "          |             \\Sequence mining-Trajectory clustering\n",
      "          |                           |\n",
      "          |                            \\-Market graph\n",
      "          |\n",
      "           \\-Formal concept analysis\n"
     ]
    }
   ],
   "source": [
    "print(convert_to_ete(tree2).get_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8c4424a-d1c1-43f5-a091-aeac6548127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           /-Data cleaning\n",
      "          |\n",
      "          |                       /-Item-based\n",
      "          |-Collaborative filtering\n",
      "          |                       \\-Scalable\n",
      "          |\n",
      "          |                 /-Types of association rules\n",
      "          |                |\n",
      "          |-Association rules-Interestingness\n",
      "          |                |\n",
      "          |                 \\-Parallel computation\n",
      "          |\n",
      "          |                                 /-Massive data clustering\n",
      "          |                                |\n",
      "          |          /Clustering feature data-Fuzzy clustering\n",
      "          |         |                      |\n",
      "          |         |                       \\-Conceptual clustering\n",
      "          |         |\n",
      "          |         |--Feature weight clustering\n",
      "          |-Clustering\n",
      "          |         |                          /-Additive clustering\n",
      "          |         |-Clustering similarity data\n",
      "          |         |                          \\-Consensus clustering\n",
      "          |         |\n",
      "          |          \\-Biclustering\n",
      "          |\n",
      "          |--Nearest-neighbor search\n",
      "-Data mining\n",
      "          |             /-Data stream mining\n",
      "          |            |\n",
      "          |            |            /-Graph partitioning\n",
      "          |            |           |\n",
      "          |            |           |--Frequent graph mining\n",
      "          |            |           |\n",
      "          |            |-Graph mining-Graph based conceptual clustering\n",
      "          |            |           |\n",
      "          |            |           |--Anomaly detection\n",
      "          |            |           |\n",
      "          |            |            \\-Critical nodes detection\n",
      "          |-Other  mining\n",
      "          |            |--Process mining\n",
      "          |            |\n",
      "          |            |           /-Text categorization\n",
      "          |            |-Text mining\n",
      "          |            |           \\-Key-phrase indexing\n",
      "          |            |\n",
      "          |            |--Data mining tools\n",
      "          |            |\n",
      "          |            |               /-Rule and pattern discovery\n",
      "          |            |              |\n",
      "          |             \\Sequence mining-Trajectory clustering\n",
      "          |                           |\n",
      "          |                            \\-Market graph\n",
      "          |\n",
      "           \\-Formal concept analysis\n"
     ]
    }
   ],
   "source": [
    "print(convert_to_ete(tree3).get_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "758a1e7f-48f1-41bd-bad5-134611806018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>root</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.2.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chimp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     0      1      2\n",
       "0      1.  root    NaN    NaN\n",
       "1    1.1.   NaN   left    NaN\n",
       "2    1.2.   NaN  right    NaN\n",
       "3  1.1.1.   NaN    NaN  human\n",
       "4  1.1.2.   NaN    NaN  horse\n",
       "5  1.2.1.   NaN    NaN  chimp"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.read_csv('test1.csv', names=[\"id\"]+list(range(3)))\n",
    "test2 = pd.read_csv('test2.csv', names=[\"id\"]+list(range(3)))\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4d8baaf-8efb-4dae-898f-bbf9cb5a0d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>root</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.2.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     0      1      2\n",
       "0      1.  root    NaN    NaN\n",
       "1    1.1.   NaN   left    NaN\n",
       "2    1.2.   NaN  right    NaN\n",
       "3  1.1.1.   NaN    NaN  human\n",
       "4  1.1.2.   NaN    NaN  chimp\n",
       "5  1.2.1.   NaN    NaN  horse"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b68ddf2-2705-47bc-a0a9-ebd332c5944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_tree = df_to_graph(test1)\n",
    "test2_tree = df_to_graph(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ae566bb-1130-4a42-9807-df1dfa203d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root ---> root\n",
      "left ---> root\n",
      "right ---> left\n",
      "human ---> human\n",
      "horse ---> horse\n",
      "chimp ---> chimp\n"
     ]
    }
   ],
   "source": [
    "map_tree(test1_tree, test2_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e1c5d-620d-4613-885c-6d2a43f175ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
