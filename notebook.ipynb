{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f0ced2",
   "metadata": {},
   "source": [
    "# Цель работы:\n",
    " Исследовать сходство и различия в толковании понятий \"machine learning\" и \"data science\" через анализ публикаций в Arxive с использованием метода обобщения в таксономиях"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba6fdf9",
   "metadata": {},
   "source": [
    "# Шаг 1\n",
    "Выделить подмножества публикаций в Arxive, ML и DS, отвечающие соответствующим запросам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946b7121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json('arxiv-metadata-oai-snapshot.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc548691",
   "metadata": {},
   "source": [
    "Filter ML and AI from past 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f5d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LG = df[df['categories'].str.contains('cs.LG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb847926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI = df[df['categories'].str.contains('cs.AI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec50dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = df[df['categories'].str.contains('stat.ML')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60468ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LG = df_LG[df_LG['update_date'] > '2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd1eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI = df_AI[df_AI['update_date'] > '2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3af7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = df_ML[df_ML['update_date'] > '2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1052a467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML articles: 42929\n",
      "AI articles: 20841\n",
      "ML (statistics) articles: 9336\n"
     ]
    }
   ],
   "source": [
    "print(f'ML articles: {len(df_LG)}')\n",
    "print(f'AI articles: {len(df_AI)}')\n",
    "print(f'ML (statistics) articles: {len(df_ML)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ce9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_LG = []\n",
    "for a in df_LG['abstract']:\n",
    "    abstracts_LG.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dcb352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_AI = []\n",
    "\n",
    "for a in df_AI['abstract']:\n",
    "    abstracts_AI.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b18f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_ML = []\n",
    "\n",
    "for a in df_ML['abstract']:\n",
    "    abstracts_ML.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ce292",
   "metadata": {},
   "source": [
    "## Шаг 2\n",
    "Выделить разумные нечеткие кластеры понятий таксономии согласно ML и согласно DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf28290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from east.asts import base\n",
    "\n",
    "\n",
    "def clear_text(text, lowerize=True):\n",
    "\n",
    "    pat = re.compile(r'[^A-Za-z0-9 \\-\\n\\r.,;!?А-Яа-я]+')\n",
    "    cleared_text = re.sub(pat, ' ', text)\n",
    "\n",
    "    if lowerize:\n",
    "        cleared_text = cleared_text.lower()\n",
    "\n",
    "    tokens = cleared_text.split()\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def make_substrings(tokens, k=4):\n",
    "\n",
    "    for i in range(max(len(tokens) - k + 1, 1)):\n",
    "        yield ' '.join(tokens[i:i + k])\n",
    "\n",
    "\n",
    "def get_corelevance_matrix(texts):\n",
    "\n",
    "    matrix = np.empty((0, len(texts)), float)\n",
    "    prepared_text_tokens = [clear_text(t) for t in texts]\n",
    "    prepared_texts = [' '.join(t) for t in prepared_text_tokens]\n",
    "\n",
    "    for text_tokens in prepared_text_tokens:\n",
    "        ast = base.AST.get_ast(list(make_substrings(text_tokens)))\n",
    "        row = np.array([ast.score(t) for t in prepared_texts])\n",
    "        matrix = np.append(matrix, [row], axis=0)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def get_relevance_matrix(texts, strings):\n",
    "\n",
    "    matrix = np.empty((0, len(strings)), float)\n",
    "    prepared_text_tokens = [clear_text(t) for t in texts]\n",
    "\n",
    "    prepared_string_tokens = [clear_text(s) for s in strings]\n",
    "    prepared_strings = [' '.join(t) for t in prepared_string_tokens]\n",
    "    \n",
    "    #for print\n",
    "    print(f'total len: {len(prepared_text_tokens)}')\n",
    "    c = 0\n",
    "\n",
    "    for text_tokens in prepared_text_tokens:\n",
    "        ast = base.AST.get_ast(list(make_substrings(text_tokens)))\n",
    "        row = np.array([ast.score(s) for s in prepared_strings])\n",
    "        matrix = np.append(matrix, [row], axis=0)\n",
    "        \n",
    "        c += 1\n",
    "        print(f'processed: {c}')\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def save_matrix(matrix, filename=\"filename\"):\n",
    "    np.savetxt(filename, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128fa077",
   "metadata": {},
   "source": [
    "Get strings of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc9bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"taxonomies/taxonomy_leaves.txt\") as f:\n",
    "    strings = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ebe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevance between the texts and strings:\n",
    "\n",
    "relevance_matrix_LG = get_relevance_matrix(abstracts_LG, strings)\n",
    "print(\"Relevance mairix LG:\")\n",
    "print(relevance_matrix_LG)\n",
    "\n",
    "save_matrix(relevance_matrix_LG, \"matrixes/relevmtx_LG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6010b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Relevance between the texts and strings:\n",
    "\n",
    "relevance_matrix_AI = get_relevance_matrix(abstracts_AI, strings)\n",
    "print(\"Relevance mairix AI:\")\n",
    "print(relevance_matrix_AI)\n",
    "\n",
    "save_matrix(relevance_matrix_AI, \"matrixes/relevmtx_AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e91f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevance between the texts and strings:\n",
    "\n",
    "relevance_matrix_ML = get_relevance_matrix(abstracts_ML, strings)\n",
    "print(\"Relevance mairix ML:\")\n",
    "print(relevance_matrix_ML)\n",
    "\n",
    "save_matrix(relevance_matrix_ML, \"matrixes/relevmtx_ML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6579bfb2",
   "metadata": {},
   "source": [
    "Obtain fuzzy clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acad27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyfaddis.lapin import lapin\n",
    "from pyfaddis.faddis import faddis\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8f34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_topics(relevance_matrix):\n",
    "    for i, row in enumerate(relevance_matrix):\n",
    "        n_i = 0\n",
    "        for j, el in enumerate(row):\n",
    "            if el > 0.3:\n",
    "                n_i += 1\n",
    "        if n_i == 0:\n",
    "            for j, el in enumerate(row):\n",
    "                relevance_matrix[i][j] = 0\n",
    "            continue\n",
    "            \n",
    "        for j, el in enumerate(row):\n",
    "            relevance_matrix[i][j] = el/n_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "528b4122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125815, 379)\n",
      "(379, 379)\n",
      "Cluster contribution is too small\n"
     ]
    }
   ],
   "source": [
    "relevance_matrix_LG = np.loadtxt(\"matrixes/relevmtx_LG\")\n",
    "print(relevance_matrix_LG.shape)\n",
    "\n",
    "normalize_topics(relevance_matrix_LG)\n",
    "\n",
    "tc = relevance_matrix_LG.T.dot(relevance_matrix_LG)\n",
    "print(tc.shape)\n",
    "\n",
    "tc_transformed = lapin(tc)\n",
    "B, member, contrib, intensity, lat, tt = faddis(tc_transformed)\n",
    "np.savetxt(\"clusters/clusters_LG.dat\", member)\n",
    "np.save(\"clusters/LG_contrib\", contrib)\n",
    "np.save(\"clusters/LG_intensity\", intensity)\n",
    "np.save(\"clusters/LG_lat\", lat)\n",
    "np.save(\"clusters/LG_tt\", tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1244883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51707, 379)\n",
      "(379, 379)\n",
      "Cluster contribution is too small\n"
     ]
    }
   ],
   "source": [
    "relevance_matrix_AI = np.loadtxt(\"matrixes/relevmtx_AI\")\n",
    "print(relevance_matrix_AI.shape)\n",
    "normalize_topics(relevance_matrix_AI)\n",
    "tc = relevance_matrix_AI.T.dot(relevance_matrix_AI)\n",
    "print(tc.shape)\n",
    "\n",
    "tc_transformed = lapin(tc)\n",
    "B, member, contrib, intensity, lat, tt = faddis(tc_transformed)\n",
    "np.savetxt(\"clusters/clusters_AI.dat\", member)\n",
    "np.save(\"clusters/AI_contrib\", contrib)\n",
    "np.save(\"clusters/AI_intensity\", intensity)\n",
    "np.save(\"clusters/AI_lat\", lat)\n",
    "np.save(\"clusters/AI_tt\", tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eceb541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9336, 379)\n",
      "(379, 379)\n",
      "Cluster contribution is too small\n"
     ]
    }
   ],
   "source": [
    "relevance_matrix_ML = np.loadtxt(\"matrixes/relevmtx_ML\")\n",
    "print(relevance_matrix_ML.shape)\n",
    "normalize_topics(relevance_matrix_ML)\n",
    "tc = relevance_matrix_ML.T.dot(relevance_matrix_ML)\n",
    "print(tc.shape)\n",
    "\n",
    "tc_transformed = lapin(tc)\n",
    "B, member, contrib, intensity, lat, tt = faddis(tc_transformed)\n",
    "np.savetxt(\"clusters/clusters_ML.dat\", member)\n",
    "np.save(\"clusters/ML_contrib\", contrib)\n",
    "np.save(\"clusters/ML_intensity\", intensity)\n",
    "np.save(\"clusters/ML_lat\", lat)\n",
    "np.save(\"clusters/ML_tt\", tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4910a",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76ee5d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML articles: 125815\n",
      "AI articles: 51707\n",
      "ML (statistics) articles: 9336\n"
     ]
    }
   ],
   "source": [
    "print(f'ML articles: {relevance_matrix_LG.shape[0]}')\n",
    "print(f'AI articles: {relevance_matrix_AI.shape[0]}')\n",
    "print(f'ML (statistics) articles: {relevance_matrix_ML.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92f322e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "member_LG = np.loadtxt('clusters/clusters_LG.dat')\n",
    "member_AI = np.loadtxt('clusters/clusters_AI.dat')\n",
    "member_ML = np.loadtxt('clusters/clusters_ML.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19075ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 3) (379, 5) (379, 5)\n"
     ]
    }
   ],
   "source": [
    "print(member_LG.shape, member_AI.shape, member_ML.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "438baf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_LG = []\n",
    "for i, el in enumerate(strings):\n",
    "    terms_LG.append((el, member_LG[i, 0], member_LG[i, 1], member_LG[i, 2]))\n",
    "\n",
    "terms_AI = []\n",
    "for i, el in enumerate(strings):\n",
    "    terms_AI.append((el, member_AI[i, 0], member_AI[i, 1], member_AI[i, 2], member_AI[i, 3], member_AI[i, 4]))\n",
    "    \n",
    "terms_ML = []\n",
    "for i, el in enumerate(strings):\n",
    "    terms_ML.append((el, member_ML[i, 0], member_ML[i, 1], member_ML[i, 2], member_ML[i, 3], member_ML[i, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238564b3",
   "metadata": {},
   "source": [
    "#### Machine Leaning (Computer Science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e73a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster contributions: [0.01692739 0.01692526 0.0033456 ]\n"
     ]
    }
   ],
   "source": [
    "contrib_LG = np.load('clusters/LG_contrib.npy')\n",
    "print(f'Cluster contributions: {contrib_LG}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75a834a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning, Cluster 1:\n",
      "cluster analysis:\t\t0.5549454007909905\n",
      "multi-agent reinforcement learning:\t\t0.33595380636547506\n",
      "information extraction:\t\t0.31555297513611746\n",
      "learning to rank:\t\t0.3152939036861742\n",
      "data provenance:\t\t0.3142129065888806\n",
      "support vector machines:\t\t0.2409914608686449\n",
      "sequential decision making:\t\t0.22789513135379083\n",
      "data exchange:\t\t0.20023478900054256\n",
      "adversarial learning:\t\t0.17243221747316048\n",
      "markov decision processes:\t\t0.15745770818135157\n",
      "boosting:\t\t0.1392249405577955\n",
      "gaussian processes:\t\t0.13505155210644487\n",
      "data cleaning:\t\t0.11781030962701397\n",
      "recommender systems:\t\t0.11212580293005102\n",
      "apprenticeship learning:\t\t0.08475824331458605\n"
     ]
    }
   ],
   "source": [
    "print('Machine Learning, Cluster 1:')\n",
    "terms_LG.sort(reverse=True, key=lambda x: x[1])\n",
    "for el in terms_LG:\n",
    "    if el[1] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca3c2c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning, Cluster 2:\n",
      "cluster analysis:\t\t0.5566761530423947\n",
      "multi-agent reinforcement learning:\t\t0.3361993303439965\n",
      "learning to rank:\t\t0.31552600514061074\n",
      "information extraction:\t\t0.3153827119858832\n",
      "data provenance:\t\t0.31447526229845785\n",
      "support vector machines:\t\t0.2408379732389745\n",
      "sequential decision making:\t\t0.22741081324050672\n",
      "data exchange:\t\t0.1998670718090123\n",
      "adversarial learning:\t\t0.17173058527541818\n",
      "markov decision processes:\t\t0.15687932436481677\n",
      "boosting:\t\t0.13865705233086464\n",
      "gaussian processes:\t\t0.13445885364091953\n",
      "data cleaning:\t\t0.11695798690403883\n",
      "recommender systems:\t\t0.11126430456500676\n",
      "apprenticeship learning:\t\t0.08372480181330283\n"
     ]
    }
   ],
   "source": [
    "print('Machine Learning, Cluster 2:')\n",
    "terms_LG.sort(reverse=True, key=lambda x: x[2])\n",
    "for el in terms_LG:\n",
    "    if el[2] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83d715d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning, Cluster 3:\n",
      "sequential decision making:\t\t0.4703981456475031\n",
      "recommender systems:\t\t0.37242375630583835\n",
      "apprenticeship learning:\t\t0.35255031914600954\n",
      "data exchange:\t\t0.32761947257467605\n",
      "gaussian processes:\t\t0.3276051237163546\n",
      "information extraction:\t\t0.2540758565002146\n",
      "data cleaning:\t\t0.20119786547199028\n",
      "support vector machines:\t\t0.20070214672177353\n",
      "inverse reinforcement learning:\t\t0.19701440057890002\n",
      "distributed database recovery:\t\t0.18381177408093108\n",
      "data provenance:\t\t0.15951872057866157\n",
      "anomaly detection:\t\t0.13926926384862984\n",
      "2d pca:\t\t0.11137371315397769\n",
      "learning to rank:\t\t0.0960608595038539\n",
      "cluster analysis:\t\t0.08485455752076987\n",
      "data locking:\t\t0.06633823139061323\n",
      "multi-agent reinforcement learning:\t\t0.052720726283058496\n",
      "markov decision processes:\t\t0.032647452068887674\n",
      "boosting:\t\t0.02858489104192856\n",
      "adversarial learning:\t\t0.020475690646848482\n",
      "markov network models:\t\t0.0003085880954526126\n",
      "bayesian networks:\t\t0.0002627319479288097\n",
      "equational models:\t\t5.274559166689788e-06\n",
      "information visualization:\t\t5.269722503057143e-06\n",
      "object identification:\t\t5.263288769328029e-06\n",
      "expectation maximization:\t\t5.2295375619044405e-06\n",
      "data integration:\t\t5.198243547849531e-06\n",
      "reconstruction:\t\t5.164845367653142e-06\n",
      "distribution functions:\t\t5.128274731364515e-06\n",
      "shape representations:\t\t5.117729220933896e-06\n",
      "feature selection:\t\t5.08158290205545e-06\n",
      "query representation:\t\t5.065582241911174e-06\n",
      "variational methods:\t\t5.05900171419144e-06\n",
      "deduplication:\t\t5.055239410919243e-06\n",
      "parallel implementation:\t\t5.0495740580082506e-06\n",
      "video segmentation:\t\t5.048686629466025e-06\n",
      "learning from demonstrations:\t\t5.0427258243850016e-06\n",
      "statistical relational learning:\t\t5.03575902981816e-06\n",
      "personalization:\t\t5.035697313326944e-06\n",
      "tensor representation:\t\t5.023786014702528e-06\n",
      "image segmentation:\t\t5.009879212664903e-06\n",
      "value iteration:\t\t4.998459661921807e-06\n",
      "active learning:\t\t4.982902678212014e-06\n",
      "relational database model:\t\t4.956181588160528e-06\n",
      "extraction transformation and loading:\t\t4.946688364716844e-06\n",
      "dimensionality reduction:\t\t4.930849109811686e-06\n",
      "random number generation:\t\t4.9257500125182764e-06\n",
      "visualization design and evaluation methods:\t\t4.909578207188763e-06\n",
      "structured prediction:\t\t4.909222253707839e-06\n",
      "query reformulation:\t\t4.900060195063864e-06\n",
      "variable elimination:\t\t4.887015797172567e-06\n",
      "source separation:\t\t4.872390910381277e-06\n",
      "natural language generation:\t\t4.8528707819390245e-06\n",
      "parallel computation:\t\t4.847808157301758e-06\n",
      "clustering and classification:\t\t4.843159836536107e-06\n",
      "stochastic differential equations:\t\t4.841915850896873e-06\n",
      "query optimization:\t\t4.841862263369173e-06\n",
      "object detection:\t\t4.837833229901647e-06\n",
      "dictionaries:\t\t4.827620772763953e-06\n",
      "hierarchical representations:\t\t4.824003025329422e-06\n",
      "machine translation:\t\t4.818327307982481e-06\n",
      "presentation of retrieval results:\t\t4.816439982807417e-06\n",
      "inductive inference:\t\t4.801908184052398e-06\n",
      "network data models:\t\t4.7908285909530235e-06\n",
      "search results deduplication:\t\t4.786605920474506e-06\n",
      "generative adversarial networks gan:\t\t4.771582556446299e-06\n",
      "supervised learning by classification:\t\t4.751272600182713e-06\n",
      "fuzzy representation:\t\t4.751130438349562e-06\n",
      "data compression:\t\t4.748035194534487e-06\n",
      "multiresolution:\t\t4.742629253550371e-06\n",
      "policy iteration:\t\t4.73727786325669e-06\n",
      "active learning settings:\t\t4.736028825596421e-06\n",
      "test collections:\t\t4.733773508288342e-06\n",
      "summarization:\t\t4.730519848397391e-06\n",
      "novelty in information retrieval:\t\t4.727868511831552e-06\n",
      "critical nodes detection:\t\t4.7223469003024695e-06\n",
      "information retrieval diversity:\t\t4.721651260997951e-06\n",
      "database query processing and optimization:\t\t4.71543497735946e-06\n",
      "appearance and texture representations:\t\t4.712317055817691e-06\n",
      "computing most probable explanation:\t\t4.708727795265783e-06\n",
      "sample complexity and generalization bounds:\t\t4.694908961845795e-06\n",
      "validation of data:\t\t4.6947471918841685e-06\n",
      "evolutionary approach:\t\t4.69157799888852e-06\n",
      "bayesian computation:\t\t4.6911927873752155e-06\n",
      "scientific visualization:\t\t4.688516642935937e-06\n",
      "database constraints theory:\t\t4.6606865805841894e-06\n",
      "text categorization:\t\t4.658244748425534e-06\n",
      "document collection models:\t\t4.657688306632892e-06\n",
      "probabilistic algorithms:\t\t4.631030021982086e-06\n",
      "retrieval effectiveness:\t\t4.623024253719506e-06\n",
      "mediators and data integration:\t\t4.616764258983305e-06\n",
      "question answering:\t\t4.613552364891341e-06\n",
      "data modeling:\t\t4.613434278511517e-06\n",
      "entity relationship models:\t\t4.611323800988843e-06\n",
      "content analysis and feature selection:\t\t4.602561142897049e-06\n",
      "tensor decomposition:\t\t4.599311427209898e-06\n",
      "graph partitioning:\t\t4.596724626355341e-06\n",
      "recurrent neural networks rnn:\t\t4.593027995999339e-06\n",
      "max marginal computation:\t\t4.591679610898297e-06\n",
      "semantic networks:\t\t4.590499887142488e-06\n",
      "modelling:\t\t4.588948218317216e-06\n",
      "hypothesis testing and confidence interval computation:\t\t4.584502775056501e-06\n",
      "latent variable models:\t\t4.5838009115612505e-06\n",
      "supervised dimesionality reduction:\t\t4.567716196312172e-06\n",
      "entity resolution:\t\t4.564862862004801e-06\n",
      "boolean function learning:\t\t4.560587099159104e-06\n",
      "tensor factorization:\t\t4.5539941907519936e-06\n",
      "temporal difference learning:\t\t4.549650271261056e-06\n",
      "instance-based learning:\t\t4.5492895778843e-06\n",
      "data encoding and canonicalization:\t\t4.5455207838676705e-06\n",
      "canonical correlation analysis:\t\t4.538083919991106e-06\n",
      "cross-validation:\t\t4.531689514831793e-06\n",
      "scalable:\t\t4.529927884803672e-06\n",
      "causal networks:\t\t4.529517680471998e-06\n",
      "inductive logic learning:\t\t4.519038485013655e-06\n",
      "models of learning:\t\t4.511559506437498e-06\n",
      "interest point and salient region detections:\t\t4.504972995510837e-06\n",
      "non-negative matrix factorization:\t\t4.497402678328496e-06\n",
      "process mining:\t\t4.493703904188571e-06\n",
      "quantile regression:\t\t4.490164756640503e-06\n",
      "cost-sensitive learning:\t\t4.48602511214661e-06\n",
      "combination fusion and federated search:\t\t4.485424192785118e-06\n",
      "empirical studies in visualization:\t\t4.482314900162237e-06\n",
      "interestingness:\t\t4.454984670489466e-06\n",
      "incomplete data:\t\t4.452351092908249e-06\n",
      "mixture modeling:\t\t4.450795608040639e-06\n",
      "rank aggregation:\t\t4.442099607153472e-06\n",
      "kernel approach:\t\t4.4330753795277385e-06\n",
      "database interoperability:\t\t4.430996515166267e-06\n",
      "object recognition:\t\t4.429739727219227e-06\n",
      "sentiment analysis:\t\t4.422325563749715e-06\n",
      "data structures and algorithms for data management:\t\t4.418745199717398e-06\n",
      "transaction logging:\t\t4.415361185413476e-06\n",
      "maximum likelihood estimation:\t\t4.413528676923822e-06\n",
      "online learning theory:\t\t4.4052188854640195e-06\n",
      "latent dirichlet allocation:\t\t4.401227396892395e-06\n",
      "multidimensional range search:\t\t4.398830972934226e-06\n",
      "speech recognition:\t\t4.380324297011509e-06\n",
      "geographic visualization:\t\t4.376349924938524e-06\n",
      "multi-agent learning:\t\t4.372208960060603e-06\n",
      "collaborative search:\t\t4.370520425404507e-06\n",
      "deep reinforcement learning drl:\t\t4.366858697599154e-06\n",
      "online learning settings:\t\t4.3637480445832885e-06\n",
      "relational parallel and distributed dbmss:\t\t4.360385365366381e-06\n",
      "inconsistent:\t\t4.359600085802614e-06\n",
      "online analytical processing engines:\t\t4.3550199641476936e-06\n",
      "robust regression:\t\t4.3513756180309e-06\n",
      "additive clustering:\t\t4.348357558630513e-06\n",
      "generalized eigenvalue:\t\t4.341949915262629e-06\n",
      "quality of the data:\t\t4.340931839377989e-06\n",
      "transfer learning:\t\t4.338458120165172e-06\n",
      "perceptron algorithm:\t\t4.332627771348767e-06\n",
      "probabilistic reasoning:\t\t4.331888497163759e-06\n",
      "mixture models:\t\t4.331601304127577e-06\n",
      "expert search:\t\t4.331115208145038e-06\n",
      "join algorithms:\t\t4.330459663608415e-06\n",
      "query suggestion:\t\t4.325460990416351e-06\n",
      "query learning:\t\t4.322111531456675e-06\n",
      "spline models:\t\t4.321823034149377e-06\n",
      "semantic inference:\t\t4.321012574080015e-06\n",
      "deep belief networks:\t\t4.318400776803638e-06\n",
      "inconsistent data:\t\t4.318239215273185e-06\n",
      "sequential monte carlo methods:\t\t4.3163314624749945e-06\n",
      "unidimensional range search:\t\t4.315174702015483e-06\n",
      "multivariate statistics:\t\t4.3058586776646046e-06\n",
      "visualization toolkits:\t\t4.304870540143602e-06\n",
      "probabilistic retrieval models:\t\t4.304852124131818e-06\n",
      "supervised learning by regression:\t\t4.303696096812098e-06\n",
      "approximate dynamic programming methods:\t\t4.300152971945568e-06\n",
      "visualization theory concepts and paradigms:\t\t4.291142496305836e-06\n",
      "independent component analysis:\t\t4.286490491569958e-06\n",
      "call level interfaces:\t\t4.276236397848309e-06\n",
      "data encryption:\t\t4.274857704802863e-06\n",
      "shape inference:\t\t4.273001997101514e-06\n",
      "hierarchical data models:\t\t4.26889053072953e-06\n",
      "nonparametric statistics:\t\t4.26319594219342e-06\n",
      "learning from critiques:\t\t4.260315875723112e-06\n",
      "frequent graph mining:\t\t4.257003600056048e-06\n",
      "massive data clustering:\t\t4.2554122975809934e-06\n",
      "contingency table analysis:\t\t4.252583938270683e-06\n",
      "kernel independent components:\t\t4.245125528925318e-06\n",
      "document structure:\t\t4.240468813827889e-06\n",
      "video search:\t\t4.23560840021452e-06\n",
      "q-learning:\t\t4.232244596065885e-06\n",
      "dbms engine architectures:\t\t4.230680763831169e-06\n",
      "image search:\t\t4.226082472273832e-06\n",
      "data stream mining:\t\t4.222333890081709e-06\n",
      "statistical graphics:\t\t4.220031871991245e-06\n",
      "formal concept analysis:\t\t4.21629265089723e-06\n",
      "batch learning:\t\t4.209580879630663e-06\n",
      "business intelligence:\t\t4.200477130916317e-06\n",
      "model trees:\t\t4.199611818135466e-06\n",
      "mathematics retrieval:\t\t4.19935822683759e-06\n",
      "maximum entropy modeling:\t\t4.197564614884611e-06\n",
      "relevance assessment:\t\t4.195377628104086e-06\n",
      "federated databases:\t\t4.19376308707922e-06\n",
      "language models:\t\t4.191673650484599e-06\n",
      "topic modeling:\t\t4.175337698778063e-06\n",
      "physical data models:\t\t4.170761197830634e-06\n",
      "partially-observable markov decision processes:\t\t4.169881736356492e-06\n",
      "traffic analysis:\t\t4.167051629153441e-06\n",
      "query intent:\t\t4.162864345956989e-06\n",
      "loopy belief propagation:\t\t4.156122939460162e-06\n",
      "rule-based netwok archirtecture:\t\t4.155408028908209e-06\n",
      "transformer nn:\t\t4.153426350605846e-06\n",
      "feature weight clustering:\t\t4.149506763912213e-06\n",
      "metropolis-hastings algorithm:\t\t4.141449452994434e-06\n",
      "enterprise search:\t\t4.123726135813141e-06\n",
      "search interfaces:\t\t4.122187720702736e-06\n",
      "bayesian nonparametric models:\t\t4.119959420165082e-06\n",
      "spectral clustering:\t\t4.119945409798714e-06\n",
      "learning under covariate shift:\t\t4.117829337295114e-06\n",
      "maximum a posteriori modeling:\t\t4.1158723095314235e-06\n",
      "queueing theory:\t\t4.112160466476109e-06\n",
      "retrieval efficiency:\t\t4.111556314569326e-06\n",
      "task models:\t\t4.111463607245488e-06\n",
      "near-duplicate and plagiarism detection:\t\t4.110657760511371e-06\n",
      "unsupervised learning and clustering:\t\t4.110154433095426e-06\n",
      "query operators:\t\t4.109117482091735e-06\n",
      "cognitive robotics:\t\t4.106417773256989e-06\n",
      "description logics:\t\t4.096913306824717e-06\n",
      "mapreduce:\t\t4.094801982424489e-06\n",
      "stream management:\t\t4.093809624309003e-06\n",
      "mapreduce-based systems:\t\t4.0904548261703446e-06\n",
      "types of association rules:\t\t4.088714979548799e-06\n",
      "fusion of classifiers:\t\t4.083644151547633e-06\n",
      "matching:\t\t4.08196745089725e-06\n",
      "uncertainty:\t\t4.072760179617817e-06\n",
      "record and buffer management:\t\t4.070558328045765e-06\n",
      "semi-supervised learning:\t\t4.067831112707119e-06\n",
      "logic and databases:\t\t4.061227892454669e-06\n",
      "lifelong machine learning:\t\t4.060154761470632e-06\n",
      "database query languages:\t\t4.057200510725856e-06\n",
      "markov-chain monte carlo convergence measures:\t\t4.057167865109001e-06\n",
      "structured text search:\t\t4.056124048593346e-06\n",
      "simulated annealing:\t\t4.052744934559959e-06\n",
      "answering queries:\t\t4.041584543493985e-06\n",
      "data mining tools:\t\t4.024652278868065e-06\n",
      "spatial and physical reasoning:\t\t4.019700288665166e-06\n",
      "structured outputs:\t\t4.0167570990742566e-06\n",
      "proximity search:\t\t4.015951594088441e-06\n",
      "conceptual design:\t\t4.009295474591165e-06\n",
      "data scans:\t\t4.009174117412361e-06\n",
      "semi-structured data:\t\t4.007897830852571e-06\n",
      "temporal reasoning:\t\t4.002716521702865e-06\n",
      "nonlinear principal components:\t\t3.99661524529076e-06\n",
      "structured query language:\t\t3.996220767767135e-06\n",
      "cloud computing:\t\t3.996208947674493e-06\n",
      "rule and pattern discovery:\t\t3.995243090305751e-06\n",
      "chemical and biochemical retrieval:\t\t3.99516953200147e-06\n",
      "thesauri:\t\t3.985413320509524e-06\n",
      "schema matching:\t\t3.980571495420745e-06\n",
      "default reasoning and belief revision:\t\t3.9795802631187465e-06\n",
      "graph embedding:\t\t3.9786316281609865e-06\n",
      "similarity measures:\t\t3.974303433409451e-06\n",
      "exploratory data analysis:\t\t3.973526009791034e-06\n",
      "conceptual clustering:\t\t3.971734244752713e-06\n",
      "decision diagrams:\t\t3.958882405553375e-06\n",
      "learning from implicit feedback:\t\t3.951601873312717e-06\n",
      "kernel density estimators:\t\t3.949419638721721e-06\n",
      "neuro-fuzzy approach:\t\t3.949406710429382e-06\n",
      "time series analysis:\t\t3.939650359052954e-06\n",
      "graph based conceptual clustering:\t\t3.938676483564453e-06\n",
      "splitting criteria:\t\t3.937066589704556e-06\n",
      "temporal data:\t\t3.929874832905607e-06\n",
      "language resources:\t\t3.9260232844403686e-06\n",
      "item-based:\t\t3.923476156090183e-06\n",
      "kernel-based clustering:\t\t3.92292976679453e-06\n",
      "document topic models:\t\t3.915255763625016e-06\n",
      "mapreduce languages:\t\t3.909988841322613e-06\n",
      "data warehouses:\t\t3.909672848786224e-06\n",
      "motif discovery:\t\t3.907078567380277e-06\n",
      "main memory engines:\t\t3.906890343994134e-06\n",
      "query planning:\t\t3.906469507503809e-06\n",
      "renewal theory:\t\t3.9033503971716895e-06\n",
      "trajectory clustering:\t\t3.901649192252595e-06\n",
      "data streams:\t\t3.894970766892592e-06\n",
      "database views:\t\t3.894164741068711e-06\n",
      "document filtering:\t\t3.891307620248418e-06\n",
      "multilingual and cross-lingual retrieval:\t\t3.890429349376875e-06\n",
      "factor analysis:\t\t3.889511780509896e-06\n",
      "consensus clustering:\t\t3.881587794871707e-06\n",
      "knowledge discovery:\t\t3.879860797306677e-06\n",
      "markov processes:\t\t3.859634282542554e-06\n",
      "tracking:\t\t3.846026260884541e-06\n",
      "web and social media search:\t\t3.845729125810432e-06\n",
      "logic programming and answer set programming:\t\t3.832517726505991e-06\n",
      "maximum likelihood modeling:\t\t3.831940457956645e-06\n",
      "theory of database privacy and security:\t\t3.82885919243411e-06\n",
      "top-k retrieval in databases:\t\t3.8263093911685545e-06\n",
      "biclustering:\t\t3.8070588592130693e-06\n",
      "xpath:\t\t3.7967428825195543e-06\n",
      "auto-encoder:\t\t3.7942880951785765e-06\n",
      "regret bounds:\t\t3.7788571872387356e-06\n",
      "survival analysis:\t\t3.7549495432135214e-06\n",
      "integrity checking:\t\t3.7528896878179074e-06\n",
      "causal reasoning and diagnostics:\t\t3.750989466984125e-06\n",
      "nearest-neighbor search:\t\t3.7358964617849195e-06\n",
      "ensembling:\t\t3.7355402064723746e-06\n",
      "bootstrapping:\t\t3.7335347518568787e-06\n",
      "wrappers:\t\t3.717458743021744e-06\n",
      "smart home:\t\t3.7126297220488084e-06\n",
      "ranking:\t\t3.7104243892113596e-06\n",
      "wikipedia based semantics:\t\t3.7077406304006e-06\n",
      "self organized map:\t\t3.7068856262962097e-06\n",
      "web log analysis:\t\t3.706640930070083e-06\n",
      "sparse tensor:\t\t3.705027967351115e-06\n",
      "dropout:\t\t3.699592816121348e-06\n",
      "stochastic games:\t\t3.699198118504393e-06\n",
      "music retrieval:\t\t3.6901614207391646e-06\n",
      "pooling:\t\t3.6862908966767118e-06\n",
      "gibbs sampling:\t\t3.6852144672273593e-06\n",
      "reasoning about belief and knowledge:\t\t3.685067554961112e-06\n",
      "discourse dialogue and pragmatics:\t\t3.673454173270836e-06\n",
      "ontology engineering:\t\t3.668285937081607e-06\n",
      "knowledge sharing:\t\t3.657476235535634e-06\n",
      "query log analysis:\t\t3.6572490861130068e-06\n",
      "key-value stores:\t\t3.6430873068292366e-06\n",
      "visual analytics:\t\t3.6290442760317697e-06\n",
      "bayesian analysis:\t\t3.6174485377600648e-06\n",
      "heat maps:\t\t3.600627595219273e-06\n",
      "least moduli:\t\t3.576462707826228e-06\n",
      "click through data:\t\t3.560079445662316e-06\n",
      "deep web:\t\t3.5396089155978352e-06\n",
      "site wrapping:\t\t3.5329243606078198e-06\n",
      "ontologies:\t\t3.532878704261268e-06\n",
      "hyperbolic trees:\t\t3.5297035815698143e-06\n",
      "key-phrase indexing:\t\t3.5266071512084205e-06\n",
      "evolving nn:\t\t3.525472612394094e-06\n",
      "factor graphs:\t\t3.5156978660420837e-06\n",
      "surfacing:\t\t3.5130680245108434e-06\n",
      "factorial hmm:\t\t3.508236421562953e-06\n",
      "speech:\t\t3.503769569033802e-06\n",
      "desktop search:\t\t3.4714488794832762e-06\n",
      "kernel matrix:\t\t3.4639950968358362e-06\n",
      "sparse pca:\t\t3.4578892621722964e-06\n",
      "triggers and rules:\t\t3.4278257080093395e-06\n",
      "knowledge graph:\t\t3.4211727619894426e-06\n",
      "graph drawings:\t\t3.4197402462687417e-06\n",
      "elastic maps:\t\t3.4184528345552455e-06\n",
      "dendrograms:\t\t3.41825585583995e-06\n",
      "xquery:\t\t3.4060737965983345e-06\n",
      "bagging:\t\t3.4039149933730437e-06\n",
      "market graph:\t\t3.3937251239613028e-06\n",
      "record and block layout:\t\t3.3408484950880572e-06\n",
      "fuzzy clustering:\t\t3.3400800809743007e-06\n",
      "taxonomy mapping:\t\t3.2902252434882506e-06\n",
      "treemaps:\t\t3.2898722848430543e-06\n",
      "jackknifing:\t\t3.285375831577691e-06\n",
      "smart city:\t\t3.256635214462648e-06\n",
      "cladograms:\t\t3.1718398694388265e-06\n",
      "point lookups:\t\t3.1015490468615436e-06\n",
      "deadlocks:\t\t3.0836553187122977e-06\n",
      "dynamic:\t\t3.0783810535379403e-06\n",
      "vagueness and fuzzy logic:\t\t3.0413118857092027e-06\n",
      "phonology:\t\t2.995797560161828e-06\n",
      "hadoop:\t\t2.6764411672428717e-06\n",
      "multi-agent reinforcement learning:\t\t0.0\n",
      "data provenance:\t\t0.0\n",
      "sequential decision making:\t\t0.0\n",
      "data exchange:\t\t0.0\n",
      "adversarial learning:\t\t0.0\n",
      "markov decision processes:\t\t0.0\n",
      "boosting:\t\t0.0\n",
      "recommender systems:\t\t0.0\n",
      "2d pca:\t\t0.0\n",
      "anomaly detection:\t\t0.0\n",
      "distributed data locking:\t\t0.0\n",
      "database recovery:\t\t0.0\n",
      "cluster analysis:\t\t0.0\n",
      "information extraction:\t\t0.0\n",
      "learning to rank:\t\t0.0\n",
      "support vector machines:\t\t0.0\n",
      "gaussian processes:\t\t0.0\n",
      "data cleaning:\t\t0.0\n",
      "apprenticeship learning:\t\t0.0\n",
      "inverse reinforcement learning:\t\t0.0\n",
      "bayesian network models:\t\t0.0\n",
      "markov networks:\t\t0.0\n"
     ]
    }
   ],
   "source": [
    "print('Machine Learning, Cluster 3:')\n",
    "terms_LG.sort(reverse=True, key=lambda x: x[3])\n",
    "for el in terms_LG:\n",
    "    if el[3] == 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef59818",
   "metadata": {},
   "source": [
    "#### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd02b543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster contributions: [0.01614585 0.01604364 0.00642044 0.00704061 0.00232388]\n"
     ]
    }
   ],
   "source": [
    "contrib_AI = np.load('clusters/AI_contrib.npy')\n",
    "print(f'Cluster contributions: {contrib_AI}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6595d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, Cluster 1:\n",
      "cluster analysis:\t\t0.49264524389990094\n",
      "information extraction:\t\t0.39266251614431313\n",
      "adversarial learning:\t\t0.3090368808866511\n",
      "apprenticeship learning:\t\t0.2969755641514707\n",
      "data cleaning:\t\t0.2963742390935148\n",
      "data provenance:\t\t0.2793264059491484\n",
      "multi-agent reinforcement learning:\t\t0.2597533222965544\n",
      "inverse reinforcement learning:\t\t0.2240701717121673\n",
      "markov decision processes:\t\t0.22171862801159653\n",
      "distributed database recovery:\t\t0.1653633818782248\n",
      "data exchange:\t\t0.1331433150899438\n",
      "learning to rank:\t\t0.13309972939696305\n",
      "2d pca:\t\t0.09264024816501125\n",
      "anomaly detection:\t\t0.08397207985560615\n"
     ]
    }
   ],
   "source": [
    "print('AI, Cluster 1:')\n",
    "terms_AI.sort(reverse=True, key=lambda x: x[1])\n",
    "for el in terms_AI:\n",
    "    if el[1] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6785319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, Cluster 2:\n",
      "cluster analysis:\t\t0.49472716378995524\n",
      "information extraction:\t\t0.3944092553549417\n",
      "adversarial learning:\t\t0.3085993610369105\n",
      "apprenticeship learning:\t\t0.2985269155349466\n",
      "data cleaning:\t\t0.29721981927620983\n",
      "data provenance:\t\t0.27759689777721874\n",
      "multi-agent reinforcement learning:\t\t0.26022315544781094\n",
      "inverse reinforcement learning:\t\t0.22574027748212083\n",
      "markov decision processes:\t\t0.2237988441847634\n",
      "data exchange:\t\t0.13446319732925904\n",
      "learning to rank:\t\t0.13280145223728063\n",
      "distributed data locking:\t\t0.12534873726392287\n",
      "database recovery:\t\t0.0997711872927268\n",
      "2d pca:\t\t0.09464273479478982\n",
      "anomaly detection:\t\t0.08121060697278178\n"
     ]
    }
   ],
   "source": [
    "print('AI, Cluster 2:')\n",
    "terms_AI.sort(reverse=True, key=lambda x: x[2])\n",
    "for el in terms_AI:\n",
    "    if el[2] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0261f2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, Cluster 3:\n",
      "2d pca:\t\t0.3989504987373712\n",
      "data provenance:\t\t0.376971977167854\n",
      "support vector machines:\t\t0.3401616027423555\n",
      "markov decision processes:\t\t0.3081722296515502\n",
      "anomaly detection:\t\t0.3052088939637672\n",
      "data exchange:\t\t0.3029558713809817\n",
      "gaussian processes:\t\t0.3005734884284608\n",
      "inverse reinforcement learning:\t\t0.28534984211874015\n",
      "adversarial learning:\t\t0.20906480653673837\n",
      "boosting:\t\t0.16621456740684418\n",
      "apprenticeship learning:\t\t0.12891434461729293\n",
      "cluster analysis:\t\t0.1117960906562706\n",
      "distributed data locking:\t\t0.09923692134770266\n",
      "sequential decision making:\t\t0.09329489353500527\n"
     ]
    }
   ],
   "source": [
    "print('AI, Cluster 3:')\n",
    "terms_AI.sort(reverse=True, key=lambda x: x[3])\n",
    "for el in terms_AI:\n",
    "    if el[3] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bcb83fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, Cluster 4:\n",
      "2d pca:\t\t0.41248969475401087\n",
      "data provenance:\t\t0.3691581957477952\n",
      "support vector machines:\t\t0.35624208117958267\n",
      "anomaly detection:\t\t0.3135740628271627\n",
      "gaussian processes:\t\t0.3120982978225472\n",
      "data exchange:\t\t0.3061260905807043\n",
      "markov decision processes:\t\t0.3022209102690163\n",
      "inverse reinforcement learning:\t\t0.27748720625730194\n",
      "adversarial learning:\t\t0.18795795516606512\n",
      "boosting:\t\t0.17510018390079676\n",
      "distributed database recovery:\t\t0.11922249146431198\n",
      "apprenticeship learning:\t\t0.1040210815727557\n",
      "sequential decision making:\t\t0.09725632599410741\n"
     ]
    }
   ],
   "source": [
    "print('AI, Cluster 4:')\n",
    "terms_AI.sort(reverse=True, key=lambda x: x[4])\n",
    "for el in terms_AI:\n",
    "    if el[4] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[4]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e4d64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, Cluster 5:\n",
      "active learning settings:\t\t0.7638199485207781\n",
      "online learning theory:\t\t0.5188313814228773\n",
      "inconsistent:\t\t0.21671652627093083\n",
      "mixture modeling:\t\t0.15583155426025344\n",
      "document topic models:\t\t0.14401678794741118\n",
      "test collections:\t\t0.08217422983710546\n"
     ]
    }
   ],
   "source": [
    "print('AI, Cluster 5:')\n",
    "terms_AI.sort(reverse=True, key=lambda x: x[5])\n",
    "for el in terms_AI:\n",
    "    if el[5] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3e03d",
   "metadata": {},
   "source": [
    "#### Machine Learning (Statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c25903fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster contributions: [0.0109593  0.0109379  0.00591683 0.00649718 0.00315163]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "contrib_ML = np.load('clusters/ML_contrib.npy')\n",
    "print(f'Cluster contributions: {contrib_ML}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "453edc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning (Statistics), Cluster 1:\n",
      "support vector machines:\t\t0.5240686712757624\n",
      "gaussian processes:\t\t0.4845274720898923\n",
      "data provenance:\t\t0.3372976940499275\n",
      "2d pca:\t\t0.33560707262928197\n",
      "sequential decision making:\t\t0.2737629062115469\n",
      "anomaly detection:\t\t0.26707278524550965\n",
      "bayesian network models:\t\t0.21292658107295484\n",
      "markov networks:\t\t0.1359470326982739\n",
      "recommender systems:\t\t0.12096745088355292\n",
      "inverse reinforcement learning:\t\t0.10122986349601061\n",
      "boosting:\t\t0.09930585707490182\n"
     ]
    }
   ],
   "source": [
    "print('Machine Learning (Statistics), Cluster 1:')\n",
    "terms_ML.sort(reverse=True, key=lambda x: x[1])\n",
    "for el in terms_ML:\n",
    "    if el[1] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c14a790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning (Statistics), Cluster 2:\n",
      "support vector machines:\t\t0.5256705700902765\n",
      "gaussian processes:\t\t0.48677073141400606\n",
      "data provenance:\t\t0.33772196449783487\n",
      "2d pca:\t\t0.3369103645223354\n",
      "sequential decision making:\t\t0.27310282881552517\n",
      "anomaly detection:\t\t0.2663413983791674\n",
      "markov network models:\t\t0.1861799234834077\n",
      "bayesian networks:\t\t0.16120439704871395\n",
      "recommender systems:\t\t0.12053424152562262\n",
      "inverse reinforcement learning:\t\t0.10085378597078183\n",
      "boosting:\t\t0.09864370067629626\n"
     ]
    }
   ],
   "source": [
    "print('Machine Learning (Statistics), Cluster 2:')\n",
    "terms_ML.sort(reverse=True, key=lambda x: x[2])\n",
    "for el in terms_ML:\n",
    "    if el[2] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4917b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning (Statistics), Cluster 3:\n",
      "sequential decision making:\t\t0.5155500146435154\n",
      "inverse reinforcement learning:\t\t0.4968479867227759\n",
      "apprenticeship learning:\t\t0.3231377455354561\n",
      "data cleaning:\t\t0.28405802108265066\n",
      "learning to rank:\t\t0.2410100686268029\n",
      "recommender systems:\t\t0.213489635933461\n",
      "gaussian processes:\t\t0.2046272929827413\n",
      "boosting:\t\t0.17887829732442265\n",
      "distributed database recovery:\t\t0.1554593518502896\n",
      "cluster analysis:\t\t0.15402236881563303\n",
      "support vector machines:\t\t0.14601005895274918\n",
      "multi-agent reinforcement learning:\t\t0.12073942310501187\n",
      "markov decision processes:\t\t0.11591681319838627\n",
      "2d pca:\t\t0.09262167933317465\n"
     ]
    }
   ],
   "source": [
    "print('Machine Learning (Statistics), Cluster 3:')\n",
    "terms_ML.sort(reverse=True, key=lambda x: x[3])\n",
    "for el in terms_ML:\n",
    "    if el[3] <= 0.08:\n",
    "        break\n",
    "    print(f'{el[0]}:\\t\\t{el[3]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
